{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQ7ghFlQYu659OF3BqGV5A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeanBarnier/HAFS_Air-Sea/blob/main/getHAFSASlices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This program subsets and saves portions of output from the MOM6 model along the track of a given TC."
      ],
      "metadata": {
        "id": "LDINAnW1dduE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set up environment"
      ],
      "metadata": {
        "id": "f592A_AhmfhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cfgrib\n",
        "!pip install cartopy\n",
        "!pip install tropycal"
      ],
      "metadata": {
        "id": "wDGgQBxjYusr",
        "collapsed": true,
        "outputId": "4df5e729-7820-4cae-fdf5-98d8f8758fb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cfgrib in /usr/local/lib/python3.11/dist-packages (0.9.15.0)\n",
            "Requirement already satisfied: attrs>=19.2 in /usr/local/lib/python3.11/dist-packages (from cfgrib) (25.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from cfgrib) (8.2.1)\n",
            "Requirement already satisfied: eccodes>=0.9.8 in /usr/local/lib/python3.11/dist-packages (from cfgrib) (2.41.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from cfgrib) (2.0.2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.11/dist-packages (from eccodes>=0.9.8->cfgrib) (1.17.1)\n",
            "Requirement already satisfied: findlibs in /usr/local/lib/python3.11/dist-packages (from eccodes>=0.9.8->cfgrib) (0.1.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi->eccodes>=0.9.8->cfgrib) (2.22)\n",
            "Requirement already satisfied: cartopy in /usr/local/lib/python3.11/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.10.0)\n",
            "Requirement already satisfied: shapely>=1.8 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.1.1)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from cartopy) (24.2)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (2.9.0.post0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj>=3.3.1->cartopy) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->cartopy) (1.17.0)\n",
            "Requirement already satisfied: tropycal in /usr/local/lib/python3.11/dist-packages (1.3)\n",
            "Requirement already satisfied: matplotlib>=2.2.2 in /usr/local/lib/python3.11/dist-packages (from tropycal) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.11/dist-packages (from tropycal) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tropycal) (1.15.3)\n",
            "Requirement already satisfied: xarray>=0.10.7 in /usr/local/lib/python3.11/dist-packages (from tropycal) (2025.3.1)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from tropycal) (2.2.2)\n",
            "Requirement already satisfied: networkx>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from tropycal) (3.5)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from tropycal) (2.32.3)\n",
            "Requirement already satisfied: pyshp>=2.1 in /usr/local/lib/python3.11/dist-packages (from tropycal) (2.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.2->tropycal) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.2->tropycal) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.2->tropycal) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.2->tropycal) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.2->tropycal) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.2->tropycal) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.2->tropycal) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.2->tropycal) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->tropycal) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->tropycal) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->tropycal) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->tropycal) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->tropycal) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->tropycal) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2.2->tropycal) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install aria2"
      ],
      "metadata": {
        "id": "ra6QPuljGkzT",
        "outputId": "75761c2d-f05d-42ac-8c11-e81881df0101",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "aria2 is already the newest version (1.36.0-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tropycal import tracks, rain\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime as dt\n",
        "import cfgrib\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "vWrr_30yZ4nh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6KsU8RFVmin5",
        "outputId": "bab208fc-7df3-4098-baab-dc300d9ef522",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#User parameters"
      ],
      "metadata": {
        "id": "XnkUgaLnLbuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"Milton\"\n",
        "tcNum = \"14\"\n",
        "filepath = f\"/content/drive/MyDrive/ColabNotebooks/{name}\"\n",
        "trackType = \"\"\n",
        "\n",
        "centralTime = dt(year=2024, month=10, day=7, hour=6) #Time when Milton began its most rapid intensification\n",
        "daysBefore = 1 #Days before the focal point\n",
        "daysAfter = 1 #Days after focal point\n",
        "\n",
        "fHourStep = 6 #Normally 3 for HAFS-A\n",
        "forecastLength = 36 #Normally 126 for HAFS-A. Changeable for testing.\n",
        "runStep = 12 #Normally 6 for HAFS-A\n",
        "\n",
        "figureSuffix = \"_RI\""
      ],
      "metadata": {
        "id": "5mX9LiKtLeTX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "atmTop = 700 # in hPa\n",
        "oceBottom = 530 # In m below surface. This was chosen to include a layer in the files that's around 529 m"
      ],
      "metadata": {
        "id": "nSPZ_yPqEe7x"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Determine Area and Temporal Extent"
      ],
      "metadata": {
        "id": "AHP_bcI8s-W6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get best track data and find bounds of TC track"
      ],
      "metadata": {
        "id": "f4C7bEjXNznh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bt = pd.read_csv(filepath + \"/hurdat2_\" + name + trackType + \".csv\")\n",
        "latBounds = [min(bt.lat), max(bt.lat)]\n",
        "lonBounds = [min(bt.lon), max(bt.lon)]"
      ],
      "metadata": {
        "id": "IwrrNNGhMYau"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dateFormat = \"%Y-%m-%d %H:%M:%S\"\n",
        "runFormat = \"%Y%m%d%H\"\n",
        "\n",
        "start = centralTime - pd.Timedelta(days=daysBefore)\n",
        "end = centralTime + pd.Timedelta(days=daysAfter)"
      ],
      "metadata": {
        "id": "N7EXfX8AgqHB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find times needed"
      ],
      "metadata": {
        "id": "aQjv2UVg4l65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fcastTimes = {} #Key: initiation, item: valid time list\n",
        "\n",
        "initTime = start\n",
        "while initTime <= end:\n",
        "  validTime = initTime\n",
        "  fcastTimes[initTime] = []\n",
        "  fhour = 0\n",
        "\n",
        "  while validTime <= end and fhour <= forecastLength:\n",
        "    fcastTimes[initTime].append(validTime)\n",
        "    validTime += pd.Timedelta(hours=fHourStep)\n",
        "    fhour += fHourStep\n",
        "\n",
        "  initTime += pd.Timedelta(hours=runStep)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jdMyhDj94ij0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Retrieve Data"
      ],
      "metadata": {
        "id": "5MU8O99TOZme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bucket = \"https://noaa-nws-hafs-pds.s3.amazonaws.com/hfsa/\"\n",
        "#atmRunSlices = [] #Holds xarray datasets for each model run\n",
        "oceRunSlices = []\n",
        "atmFiles = []\n",
        "oceFiles = []"
      ],
      "metadata": {
        "id": "_4qJFbXFBzK4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for init, validList in fcastTimes.items():\n",
        "\n",
        "  initDate, initHour = init.strftime(\"%Y%m%d_%H\").split(\"_\")\n",
        "  atmRun = False\n",
        "\n",
        "  for valid in validList:\n",
        "\n",
        "    fhour = str(int((valid-init).total_seconds() / 3600))\n",
        "    while len(fhour) < 3: fhour = \"0\" + fhour\n",
        "\n",
        "    atmURL = bucket + initDate + \"/\" + initHour + \"/\" + tcNum + \"l.\" + initDate + initHour + \".hfsa.storm.atm.f\" + fhour + \".grb2\"\n",
        "    atmFile = \"atm_\" + initDate + \"_\" + initHour + \"_f\" + fhour + \".grb2\"\n",
        "    atmFiles.append(atmFile)\n",
        "\n",
        "    !aria2c -x 16 -s 16 --allow-overwrite=true -o {atmFile} {atmURL}\n",
        "\n",
        "    atmData = xr.open_dataset(atmFile, engine=\"cfgrib\", decode_timedelta=True, filter_by_keys={'stepType': 'instant', 'typeOfLevel': 'isobaricInhPa'})\n",
        "\n",
        "    pressureSlice = slice(max(atmData.isobaricInhPa.data), atmTop)\n",
        "    #Longitude in atm files are in degrees east, but are -180 - 180 in oce files. point has them from -180 - 180\n",
        "    atmSlice = atmData.sel(latitude=slice(latBounds[0], latBounds[1]), longitude=slice(360+lonBounds[0], 360+lonBounds[1]), isobaricInhPa=pressureSlice)\n",
        "\n",
        "    if atmRun == False: atmRun = atmSlice #DEBUG\n",
        "    else: atmRun = xr.concat((atmRun, atmSlice), dim=\"valid_time\")\n",
        "\n",
        "  atmRun.to_netcdf(\"hafsa_\" + initDate + initHour + \".nc\")\n",
        "\n",
        "  #for file in atmFiles:\n",
        "  #  !rm {file}\n",
        "  #atmFiles = []\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZPGYEMDlF2T",
        "outputId": "605b43f2-3d80-4666-89a0-68613bb8c98b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "06/16 23:04:54 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
            "\u001b[0m\n",
            "06/16 23:04:57 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /content/atm_20241006_06_f000.grb2\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "144e99|\u001b[1;32mOK\u001b[0m  |   121MiB/s|/content/atm_20241006_06_f000.grb2\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cfgrib.messages:Ignoring index file 'atm_20241006_06_f000.grb2.5b7b6.idx' older than GRIB file\n",
            "ERROR:cfgrib.dataset:skipping variable: paramId==3017 shortName='dpt'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cfgrib/dataset.py\", line 725, in build_dataset_components\n",
            "    dict_merge(variables, coord_vars)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cfgrib/dataset.py\", line 641, in dict_merge\n",
            "    raise DatasetBuildError(\n",
            "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='isobaricInhPa' value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  875.,  850.,  825.,  800.,\n",
            "        775.,  750.,  725.,  700.,  675.,  650.,  625.,  600.,  575.,\n",
            "        550.,  525.,  500.,  475.,  450.,  425.,  400.,  375.,  350.,\n",
            "        325.,  300.,  275.,  250.,  225.,  200.,  175.,  150.,  125.,\n",
            "        100.,   70.,   50.,   30.,   20.,   10.,    7.,    5.,    2.])) new_value=Variable(dimensions=('isobaricInhPa',), data=array([850., 700., 500., 300., 200., 100.]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "06/16 23:05:00 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
            "\u001b[0m\n",
            "06/16 23:05:02 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /content/atm_20241006_06_f006.grb2\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "15dbc8|\u001b[1;32mOK\u001b[0m  |   137MiB/s|/content/atm_20241006_06_f006.grb2\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cfgrib.messages:Ignoring index file 'atm_20241006_06_f006.grb2.5b7b6.idx' older than GRIB file\n",
            "ERROR:cfgrib.dataset:skipping variable: paramId==3017 shortName='dpt'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cfgrib/dataset.py\", line 725, in build_dataset_components\n",
            "    dict_merge(variables, coord_vars)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cfgrib/dataset.py\", line 641, in dict_merge\n",
            "    raise DatasetBuildError(\n",
            "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='isobaricInhPa' value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  875.,  850.,  825.,  800.,\n",
            "        775.,  750.,  725.,  700.,  675.,  650.,  625.,  600.,  575.,\n",
            "        550.,  525.,  500.,  475.,  450.,  425.,  400.,  375.,  350.,\n",
            "        325.,  300.,  275.,  250.,  225.,  200.,  175.,  150.,  125.,\n",
            "        100.,   70.,   50.,   30.,   20.,   10.,    7.,    5.,    2.])) new_value=Variable(dimensions=('isobaricInhPa',), data=array([850., 700., 500., 300., 200., 100.]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "06/16 23:05:10 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
            "\u001b[0m\n",
            "06/16 23:05:12 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /content/atm_20241006_06_f012.grb2\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "c86c58|\u001b[1;32mOK\u001b[0m  |   130MiB/s|/content/atm_20241006_06_f012.grb2\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cfgrib.messages:Ignoring index file 'atm_20241006_06_f012.grb2.5b7b6.idx' older than GRIB file\n",
            "ERROR:cfgrib.dataset:skipping variable: paramId==3017 shortName='dpt'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cfgrib/dataset.py\", line 725, in build_dataset_components\n",
            "    dict_merge(variables, coord_vars)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cfgrib/dataset.py\", line 641, in dict_merge\n",
            "    raise DatasetBuildError(\n",
            "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='isobaricInhPa' value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  875.,  850.,  825.,  800.,\n",
            "        775.,  750.,  725.,  700.,  675.,  650.,  625.,  600.,  575.,\n",
            "        550.,  525.,  500.,  475.,  450.,  425.,  400.,  375.,  350.,\n",
            "        325.,  300.,  275.,  250.,  225.,  200.,  175.,  150.,  125.,\n",
            "        100.,   70.,   50.,   30.,   20.,   10.,    7.,    5.,    2.])) new_value=Variable(dimensions=('isobaricInhPa',), data=array([850., 700., 500., 300., 200., 100.]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "06/16 23:05:21 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
            "\u001b[0m\n",
            "06/16 23:05:23 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /content/atm_20241006_06_f018.grb2\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "3177ca|\u001b[1;32mOK\u001b[0m  |   145MiB/s|/content/atm_20241006_06_f018.grb2\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cfgrib.messages:Ignoring index file 'atm_20241006_06_f018.grb2.5b7b6.idx' older than GRIB file\n",
            "ERROR:cfgrib.dataset:skipping variable: paramId==3017 shortName='dpt'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cfgrib/dataset.py\", line 725, in build_dataset_components\n",
            "    dict_merge(variables, coord_vars)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cfgrib/dataset.py\", line 641, in dict_merge\n",
            "    raise DatasetBuildError(\n",
            "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='isobaricInhPa' value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  875.,  850.,  825.,  800.,\n",
            "        775.,  750.,  725.,  700.,  675.,  650.,  625.,  600.,  575.,\n",
            "        550.,  525.,  500.,  475.,  450.,  425.,  400.,  375.,  350.,\n",
            "        325.,  300.,  275.,  250.,  225.,  200.,  175.,  150.,  125.,\n",
            "        100.,   70.,   50.,   30.,   20.,   10.,    7.,    5.,    2.])) new_value=Variable(dimensions=('isobaricInhPa',), data=array([850., 700., 500., 300., 200., 100.]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "06/16 23:05:32 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
            "\u001b[0m\n",
            "06/16 23:05:34 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /content/atm_20241006_06_f024.grb2\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "daabc8|\u001b[1;32mOK\u001b[0m  |   138MiB/s|/content/atm_20241006_06_f024.grb2\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cfgrib.messages:Ignoring index file 'atm_20241006_06_f024.grb2.5b7b6.idx' older than GRIB file\n",
            "ERROR:cfgrib.dataset:skipping variable: paramId==3017 shortName='dpt'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cfgrib/dataset.py\", line 725, in build_dataset_components\n",
            "    dict_merge(variables, coord_vars)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cfgrib/dataset.py\", line 641, in dict_merge\n",
            "    raise DatasetBuildError(\n",
            "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='isobaricInhPa' value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  875.,  850.,  825.,  800.,\n",
            "        775.,  750.,  725.,  700.,  675.,  650.,  625.,  600.,  575.,\n",
            "        550.,  525.,  500.,  475.,  450.,  425.,  400.,  375.,  350.,\n",
            "        325.,  300.,  275.,  250.,  225.,  200.,  175.,  150.,  125.,\n",
            "        100.,   70.,   50.,   30.,   20.,   10.,    7.,    5.,    2.])) new_value=Variable(dimensions=('isobaricInhPa',), data=array([850., 700., 500., 300., 200., 100.]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "06/16 23:05:43 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
            "\u001b[0m\n",
            "06/16 23:05:45 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /content/atm_20241006_06_f030.grb2\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "18e72f|\u001b[1;32mOK\u001b[0m  |   121MiB/s|/content/atm_20241006_06_f030.grb2\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cfgrib.messages:Ignoring index file 'atm_20241006_06_f030.grb2.5b7b6.idx' older than GRIB file\n",
            "ERROR:cfgrib.dataset:skipping variable: paramId==3017 shortName='dpt'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cfgrib/dataset.py\", line 725, in build_dataset_components\n",
            "    dict_merge(variables, coord_vars)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cfgrib/dataset.py\", line 641, in dict_merge\n",
            "    raise DatasetBuildError(\n",
            "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='isobaricInhPa' value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  875.,  850.,  825.,  800.,\n",
            "        775.,  750.,  725.,  700.,  675.,  650.,  625.,  600.,  575.,\n",
            "        550.,  525.,  500.,  475.,  450.,  425.,  400.,  375.,  350.,\n",
            "        325.,  300.,  275.,  250.,  225.,  200.,  175.,  150.,  125.,\n",
            "        100.,   70.,   50.,   30.,   20.,   10.,    7.,    5.,    2.])) new_value=Variable(dimensions=('isobaricInhPa',), data=array([850., 700., 500., 300., 200., 100.]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "06/16 23:05:55 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
            "\u001b[0m\n",
            "06/16 23:05:58 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /content/atm_20241006_06_f036.grb2\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "368e2a|\u001b[1;32mOK\u001b[0m  |   126MiB/s|/content/atm_20241006_06_f036.grb2\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cfgrib.messages:Ignoring index file 'atm_20241006_06_f036.grb2.5b7b6.idx' older than GRIB file\n",
            "ERROR:cfgrib.dataset:skipping variable: paramId==3017 shortName='dpt'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cfgrib/dataset.py\", line 725, in build_dataset_components\n",
            "    dict_merge(variables, coord_vars)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cfgrib/dataset.py\", line 641, in dict_merge\n",
            "    raise DatasetBuildError(\n",
            "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='isobaricInhPa' value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  875.,  850.,  825.,  800.,\n",
            "        775.,  750.,  725.,  700.,  675.,  650.,  625.,  600.,  575.,\n",
            "        550.,  525.,  500.,  475.,  450.,  425.,  400.,  375.,  350.,\n",
            "        325.,  300.,  275.,  250.,  225.,  200.,  175.,  150.,  125.,\n",
            "        100.,   70.,   50.,   30.,   20.,   10.,    7.,    5.,    2.])) new_value=Variable(dimensions=('isobaricInhPa',), data=array([850., 700., 500., 300., 200., 100.]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atmRun.step.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWPnBjvi9SjR",
        "outputId": "758562e0-7084-4368-9fd9-209c02fa5090"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(129600000000000, dtype='timedelta64[ns]')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atmSlice.step.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjHhCv1-_3a4",
        "outputId": "2dcf91b9-694a-4763-aae6-6eeb8510793f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(129600000000000, dtype='timedelta64[ns]')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atmRun = xr.open_dataset(\"hafsa_\" + initDate + initHour + \".nc\", decode_timedelta=False)"
      ],
      "metadata": {
        "id": "SjosWq1i1d6R"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for init, validList in fcastTimes.items():\n",
        "\n",
        "  initDate, initHour = init.strftime(\"%Y%m%d_%H\").split(\"_\")\n",
        "  oceRun = False\n",
        "\n",
        "  for valid in validList:\n",
        "\n",
        "    fhour = str(int((valid-init).total_seconds() / 3600))\n",
        "    while len(fhour) < 3: fhour = \"0\" + fhour\n",
        "\n",
        "    oceURL = bucket + initDate + \"/\" + initHour + \"/\" + tcNum + \"l.\" + initDate + initHour + \".hfsa.mom6.f\" + fhour + \".nc\"\n",
        "    oceFile = \"oce_\" + initDate + \"_\" + initHour + \"_f\" + fhour + \".nc\"\n",
        "\n",
        "    #if oceFile != 'oce_20241008_00_f000.nc': #This file is missing\n",
        "    !aria2c -x 16 -s 16 --allow-overwrite=true -o {oceFile} {oceURL}\n",
        "    oceData = xr.open_dataset(oceFile, decode_times=False)\n",
        "\n",
        "    depthSlice = slice(min(oceData.z_l.data), oceBottom)\n",
        "    oceSlice = oceData.sel(z_l=depthSlice, z_i=depthSlice,\\\n",
        "                           xh=slice(lonBounds[0],lonBounds[1]), yh=slice(latBounds[0],latBounds[1]),\\\n",
        "                           xq=slice(lonBounds[0],lonBounds[1]), yq=slice(latBounds[0],latBounds[1]))\n",
        "\n",
        "    if oceRun == False: oceRun = oceSlice\n",
        "    else: oceRun = xr.concat((oceRun, oceSlice), dim=\"valid\")\n",
        "\n",
        "  oceRun.to_netcdf(\"mom6_\" + initDate + initHour + \".nc\")\n",
        "\n",
        "  for file in oceFiles:\n",
        "    !rm {oceFile}\n",
        "  oceFiles = []\n",
        "\n",
        "  !rm {oceFile}"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mU1HIzL_4ij2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}