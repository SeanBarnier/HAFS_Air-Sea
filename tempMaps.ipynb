{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZIhxnNH/OqeQzt2x9SKvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeanBarnier/HAFS_Air-Sea/blob/main/tempMaps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set up environment"
      ],
      "metadata": {
        "id": "f592A_AhmfhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6KsU8RFVmin5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cfgrib\n",
        "!pip install cartopy"
      ],
      "metadata": {
        "id": "wDGgQBxjYusr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cft\n",
        "from datetime import datetime as dt\n",
        "import cfgrib"
      ],
      "metadata": {
        "id": "vWrr_30yZ4nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#User parameters"
      ],
      "metadata": {
        "id": "XnkUgaLnLbuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"Milton\"\n",
        "tcNum = \"14\"\n",
        "trackType = \"\"\n",
        "\n",
        "initTime = dt(year=2024, month=10, day=7, hour=12) #Time when Milton began its most rapid intensification\n",
        "\n",
        "fHourStep = 12      #Normally 3 for HAFS-A\n",
        "forecastLength = 36 #Normally 126 for HAFS-A.\n",
        "#runStep = 6         #Normally 6 for HAFS-A\n",
        "\n",
        "figureSuffix = \"_RI\"\n",
        "subfolder = \"RI/\"\n",
        "dataPath = \"/content/drive/MyDrive/savedData/\"\n",
        "figurePath = \"/content/drive/MyDrive/figures/\"\n",
        "\n",
        "potentialTemp = True #Use atmospheric potential temperature instead of in-situ temperature\n",
        "\n",
        "radType = \"dist\" # \"wind\", \"dist\", or None\n",
        "windRad = 34 # wind radius in kt to plot; only matters if radType = \"wind\"\n",
        "dist = 1.0 # in degrees; only matters if radType = \"dist\""
      ],
      "metadata": {
        "id": "5mX9LiKtLeTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Retrieve HAFS-A Data"
      ],
      "metadata": {
        "id": "5MU8O99TOZme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find times needed"
      ],
      "metadata": {
        "id": "aQjv2UVg4l65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dateFormat = \"%Y-%m-%d %H:%M:%S\"\n",
        "runFormat = \"%Y%m%d%H\"\n",
        "\n",
        "#Times to plot\n",
        "fcastTimes = [] #Key: initiation, item: valid time list\n",
        "fhour = 0\n",
        "validTime = initTime\n",
        "while fhour <= forecastLength:\n",
        "    fcastTimes.append(validTime)\n",
        "    validTime += pd.Timedelta(hours=fHourStep)\n",
        "    fhour += fHourStep\n",
        "\n",
        "#All forecast times\n",
        "allTimes = [] #Key: initiation, item: valid time list\n",
        "fhour = 0\n",
        "validTime = initTime\n",
        "while fhour <= forecastLength:\n",
        "    allTimes.append(validTime)\n",
        "    validTime += pd.Timedelta(hours=3)\n",
        "    fhour += 3"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jdMyhDj94ij0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find storm location in HAFS-A from ATCF files. Used to find along-storm profile."
      ],
      "metadata": {
        "id": "bNcDi6valX_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"BASIN\", \"CY\", \"YYYYMMDDHH\", \"TECHNUM/MIN\", \"TECH\", \"TAU\", \"LatN/S\", \"LonE/W\",\n",
        "    \"VMAX\", \"MSLP\", \"TY\", \"RAD\", \"WINDCODE\", \"RAD1\", \"RAD2\", \"RAD3\", \"RAD4\",\n",
        "    \"POUTER\", \"ROUTER\", \"RMW\", \"GUSTS\", \"EYE\", \"SUBREGION\", \"MAXSEAS\", \"INITIALS\",\n",
        "    \"DIR\", \"SPEED\", \"STORMNAME\", \"DEPTH\", \"SEAS\", \"SEASCODE\", \"SEAS1\", \"SEAS2\",\n",
        "    \"SEAS3\", \"SEAS4\", \"USERDEFINED1\", \"Thermo1\", \"Thermo2\", \"Thermo3\", \"Thermo4\",\n",
        "    \"Thermo5\", \"Thermo6\", \"Thermo7\", \"USERDEFINED2\", \"DT\", \"SHR82\", \"SHR81_1\",\n",
        "    \"SHR82_2\",  \"USERDEFINED3\", \"SST\", \"USERDEFINED4\", \"ARMW1\", \"ARMW2\"]\n",
        "\n",
        "initStr, initHour = initTime.strftime(\"%Y%m%d_%H\").split(\"_\")\n",
        "\n",
        "atcfURL = f\"https://noaa-nws-hafs-pds.s3.amazonaws.com/hfsa/{initStr}/{initHour}/{tcNum}l.{initStr}{initHour}.hfsa.trak.atcfunix\"\n",
        "atcfFile = \"atcf_\" + initStr + \"_\" + initHour + \".csv\"\n",
        "\n",
        "!wget -O {atcfFile} {atcfURL}\n",
        "atcf = pd.read_csv(atcfFile, names=cols)"
      ],
      "metadata": {
        "id": "yO6jA18GOCVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tcLocs = {}\n",
        "windRads = {}\n",
        "\n",
        "for valid in allTimes:\n",
        "    fHour = int((valid-initTime).total_seconds() / 3600)\n",
        "\n",
        "    pointLat = int(atcf[atcf.TAU==fHour][\"LatN/S\"].iloc[0].replace(\"N\", \"\"))/10\n",
        "    pointLon = int(atcf[atcf.TAU==fHour][\"LonE/W\"].iloc[0].replace(\"W\", \"\"))/-10 #Assume western hemisphere\n",
        "    tcLocs[valid] = (pointLat, pointLon)\n",
        "\n",
        "    #if windRad == \"RMW\": windRads[runTime][valid] = atcf[atcf.TAU==fHour][\"RMW\"].iloc[0]\n",
        "    #else:\n",
        "    windRadData = atcf[atcf.RAD==windRad][atcf.TAU==fHour]\n",
        "    if len(windRadData) == 0: windRads[valid] = 0 #If there is no radius for a given wind value, the TC does not posess that wind value\n",
        "    # Get smallest radius; outside this, the wind will be less than 34kt in one quadrant\n",
        "    else: windRads[valid] = np.min([windRadData[\"RAD1\"], windRadData[\"RAD2\"], windRadData[\"RAD3\"], windRadData[\"RAD4\"]]) / 60 # Convert from n mi to degrees"
      ],
      "metadata": {
        "id": "M2-eqEmxlXw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Figures"
      ],
      "metadata": {
        "id": "ya_eLEMjx7tf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Figure Parameters"
      ],
      "metadata": {
        "id": "BBSBA8q9noOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lonMin, lonMax, latMin, latMax = -95, -82, 20, 27\n",
        "\n",
        "atmLayers = [0, 1, 2, 3, 4, 5, 6]\n",
        "oceLayers = [0, 1, 2, 3, 4, 5, 6]\n",
        "\n",
        "buffer = 0.1 / len(atmLayers)\n",
        "xWidth = 0.8 / len(fcastTimes)\n",
        "yWidth = 0.4 / len(atmLayers)\n",
        "xcorners = np.arange(0.1,0.9,xWidth)\n",
        "ycorners = np.arange(0.7,0.3,-yWidth)\n",
        "\n",
        "diffType = \"top\" #top or incremental"
      ],
      "metadata": {
        "id": "sFJs72fTx9KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Atmospheric Temperature"
      ],
      "metadata": {
        "id": "prWGu4LUnyGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "atmFig = plt.figure(figsize=(len(fcastTimes)*5,len(atmLayers)*6))\n",
        "atmAxes = [[atmFig.add_axes([xcorner, ycorner, xWidth-buffer, yWidth-buffer], projection=ccrs.PlateCarree()) for ycorner in ycorners] for xcorner in xcorners]\n",
        "\n",
        "contourLevs = {layer:[\"Empty\"] for layer in atmLayers}\n",
        "for valid, atmAxColumn in zip(fcastTimes, atmAxes):\n",
        "\n",
        "  fhour = str(int((valid-initTime).total_seconds() / 3600))\n",
        "  while len(fhour) < 3: fhour = \"0\" + fhour\n",
        "\n",
        "  atmFile = \"hafsa_\" + initStr + initHour + \"_f\" + fhour + \".nc\"\n",
        "  atmPath = dataPath + \"hafsaOutput/\" + subfolder + atmFile\n",
        "  atmData = xr.open_dataset(atmPath)\n",
        "\n",
        "  for atmLayer, atmAx in zip(atmLayers, atmAxColumn):\n",
        "\n",
        "    atmSlice = atmData.isel(isobaricInhPa=atmLayer).sel(longitude=slice(lonMin+360, lonMax+360), latitude=slice(latMin, latMax))\n",
        "\n",
        "    if potentialTemp: temp = atmSlice.t.data * (1000/atmSlice.isobaricInhPa.data) ** 0.286\n",
        "    else: temp = atmSlice.t.data\n",
        "\n",
        "    if \"Empty\" in contourLevs[atmLayer]: contourLevs[atmLayer] = [round(l, 1) for l in np.linspace(np.min(temp[np.isnan(temp)==False])-3, np.max(temp[np.isnan(temp)==False])+3, 15)]\n",
        "\n",
        "    tempContour = atmAx.contourf(atmSlice.longitude.data, atmSlice.latitude.data, temp, cmap=\"coolwarm\", transform=ccrs.PlateCarree(),\n",
        "                                extent = [lonMin, lonMax, latMin, latMax], levels=contourLevs[atmLayer])\n",
        "\n",
        "    if valid == fcastTimes[-1]: atmFig.colorbar(tempContour, shrink=0.8)\n",
        "\n",
        "    #atmAx.scatter(tcLocs[valid][1], tcLocs[valid][0], marker=\"*\", color=\"black\", s=75, transform=ccrs.PlateCarree())\n",
        "\n",
        "    atmAx.add_feature(cft.COASTLINE)\n",
        "    atmAx.add_feature(cft.BORDERS)\n",
        "    atmAx.gridlines(draw_labels=[\"left\", \"bottom\"], alpha=0.5)\n",
        "    atmAx.set_title(f'{atmData.isobaricInhPa.data[atmLayer]} hPa\\n{valid.strftime(\"%Y-%m-%d %HUTC\")}')\n",
        "\n",
        "    atmAx.set_extent([lonMin, lonMax, latMin, latMax])\n",
        "\n",
        "#atmFig.suptitle(f\"Atmosphere Initialized {initTime.strftime('%Y-%m-%d %HUTC')}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mU1HIzL_4ij2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oceanic Temperature"
      ],
      "metadata": {
        "id": "Z70LZu5qn7_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oceFig = plt.figure(figsize=(len(fcastTimes)*5,len(oceLayers)*6))\n",
        "oceAxes = [[oceFig.add_axes([xcorner, ycorner, xWidth-buffer, yWidth-buffer], projection=ccrs.PlateCarree()) for ycorner in ycorners] for xcorner in xcorners]\n",
        "\n",
        "contourLevs = {layer:[\"Empty\"] for layer in atmLayers}\n",
        "\n",
        "for valid, oceAxColumn in zip(fcastTimes, oceAxes):\n",
        "\n",
        "  fhour = str(int((valid-initTime).total_seconds() / 3600))\n",
        "  while len(fhour) < 3: fhour = \"0\" + fhour\n",
        "\n",
        "  oceFile = \"mom6_\" + initStr + initHour + \"_f\" + fhour + \".nc\"\n",
        "  ocePath = dataPath + \"mom6Output/\" + subfolder + oceFile\n",
        "  oceData = xr.open_dataset(ocePath, decode_times=False)\n",
        "\n",
        "  for oceLayer, oceAx in zip(oceLayers, oceAxColumn):\n",
        "\n",
        "    oceSlice = oceData.isel(z_l=oceLayer).sel(xh=slice(lonMin, lonMax), yh=slice(latMin, latMax), time=oceData.time.data[0])\n",
        "\n",
        "    temp = oceSlice.temp.data + 273.15\n",
        "    if \"Empty\" in contourLevs[oceLayer]: contourLevs[oceLayer] = [round(l, 1) for l in np.linspace(min(temp[np.isnan(temp)==False])-1, max(temp[np.isnan(temp)==False])+1, 15)]\n",
        "\n",
        "    tempContour = oceAx.contourf(oceSlice.xh.data, oceSlice.yh.data, temp, cmap=\"coolwarm\", transform=ccrs.PlateCarree(),\n",
        "                                extent=[lonMin, lonMax, latMin, latMax], levels=contourLevs[oceLayer])\n",
        "    if valid == fcastTimes[-1]: oceFig.colorbar(tempContour, shrink=0.8, label=\"Temperature (K)\")\n",
        "\n",
        "    oceAx.scatter(tcLocs[valid][1], tcLocs[valid][0], marker=\"*\", color=\"black\", s=100, transform=ccrs.PlateCarree())\n",
        "\n",
        "    gridLabels = []\n",
        "    if oceLayer == oceLayers[-1]: gridLabels.append(\"bottom\")\n",
        "    if valid == fcastTimes[0]: gridLabels.append(\"left\")\n",
        "    oceAx.gridlines(draw_labels=gridLabels, alpha=0.5)\n",
        "\n",
        "    oceAx.add_feature(cft.COASTLINE)\n",
        "    oceAx.add_feature(cft.BORDERS)\n",
        "    oceAx.set_title(f\"{round(oceData.z_l.data[oceLayer],1)} m\\n{valid.strftime('%Y-%m-%d %HUTC')}\")\n",
        "\n",
        "    oceAx.set_extent([lonMin, lonMax, latMin, latMax])\n",
        "\n",
        "#oceFig.suptitle(f\"Initialized {initTime.strftime('%Y-%m-%d %HUTC')}\")"
      ],
      "metadata": {
        "id": "BGzvH0yGl85S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Atmosphere Temperature Difference by Level"
      ],
      "metadata": {
        "id": "p2yHo_lOAOmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "atmFig = plt.figure(figsize=(len(fcastTimes)*5,len(atmLayers)*6))\n",
        "atmAxes = [[atmFig.add_axes([xcorner, ycorner, xWidth-buffer, yWidth-buffer], projection=ccrs.PlateCarree()) for ycorner in ycorners[:-1]] for xcorner in xcorners]\n",
        "\n",
        "contourLevs = {layer:[\"Empty\"] for layer in atmLayers}\n",
        "for valid, atmAxColumn in zip(fcastTimes, atmAxes):\n",
        "\n",
        "  fhour = str(int((valid-initTime).total_seconds() / 3600))\n",
        "  while len(fhour) < 3: fhour = \"0\" + fhour\n",
        "\n",
        "  atmFile = \"hafsa_\" + initStr + initHour + \"_f\" + fhour + \".nc\"\n",
        "  atmPath = dataPath + \"hafsaOutput/\" + subfolder + atmFile\n",
        "  atmData = xr.open_dataset(atmPath)\n",
        "\n",
        "  lowerLayers = {\"top\":[0]*len(atmLayers[:-1]), \"incremental\":atmLayers[1:]}[diffType]\n",
        "  for upperLayer, lowerLayer, atmAx in zip(atmLayers[1:], lowerLayers, atmAxColumn):\n",
        "\n",
        "    upperSlice = atmData.isel(isobaricInhPa=upperLayer).sel(longitude=slice(lonMin+360, lonMax+360), latitude=slice(latMin, latMax))\n",
        "    lowerSlice = atmData.isel(isobaricInhPa=lowerLayer).sel(longitude=slice(lonMin+360, lonMax+360), latitude=slice(latMin, latMax))\n",
        "\n",
        "    if potentialTemp: tdiff = (upperSlice.t.data * (1000/atmSlice.isobaricInhPa.data) ** 0.286) - (lowerSlice.t.data * (1000/atmSlice.isobaricInhPa.data) ** 0.286)\n",
        "    else: tdiff = upperSlice.t.data - lowerSlice.t.data\n",
        "\n",
        "    if \"Empty\" in contourLevs[upperLayer]: contourLevs[upperLayer] = np.round(np.linspace(-1*(np.max(abs(tdiff[np.isnan(tdiff)==False]))+1), np.max(abs(tdiff[np.isnan(tdiff)==False]))+1, 15), 2)\n",
        "\n",
        "    tempContour = atmAx.contourf(upperSlice.longitude.data, upperSlice.latitude.data, tdiff, cmap=\"bwr\", transform=ccrs.PlateCarree(),\n",
        "                                extent = [lonMin, lonMax, latMin, latMax], levels=contourLevs[upperLayer])\n",
        "    if valid == fcastTimes[-1]: atmFig.colorbar(tempContour, shrink=0.8, label=f\"T(z={int(atmData.isobaricInhPa.data[upperLayer])}) - T(z={int(atmData.isobaricInhPa.data[lowerLayer])})\")\n",
        "\n",
        "    #atmAx.scatter(tcLocs[valid][1], tcLocs[valid][0], marker=\"*\", color=\"black\", s=75, transform=ccrs.PlateCarree())\n",
        "    gridLabels = []\n",
        "    if lowerLayer == oceLayers[-1]: gridLabels.append(\"bottom\")\n",
        "    if valid == fcastTimes[0]: gridLabels.append(\"left\")\n",
        "    atmAx.gridlines(draw_labels=gridLabels, alpha=0.5)\n",
        "\n",
        "    atmAx.add_feature(cft.COASTLINE)\n",
        "    atmAx.add_feature(cft.BORDERS)\n",
        "    atmAx.set_title(valid.strftime(\"%Y-%m-%d %HUTC\"))\n",
        "\n",
        "    atmAx.set_extent([lonMin, lonMax, latMin, latMax])\n",
        "\n",
        "#atmFig.suptitle(f\"Atmosphere Initialized {initTime.strftime('%Y-%m-%d %HUTC')}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "izfpsMeQD8J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ocean Temperature Difference by Level"
      ],
      "metadata": {
        "id": "hV_P36LloDzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oceFig = plt.figure(figsize=(len(fcastTimes)*6,len(oceLayers)*7))\n",
        "oceAxes = [[oceFig.add_axes([xcorner, ycorner, xWidth-buffer, yWidth-buffer], projection=ccrs.PlateCarree()) for ycorner in ycorners[:-1]] for xcorner in xcorners]\n",
        "\n",
        "contourLevs = {layer:[\"Empty\"] for layer in oceLayers}\n",
        "\n",
        "for valid, oceAxColumn in zip(fcastTimes, oceAxes):\n",
        "\n",
        "  fhour = str(int((valid-initTime).total_seconds() / 3600))\n",
        "  while len(fhour) < 3: fhour = \"0\" + fhour\n",
        "\n",
        "  oceFile = \"mom6_\" + initStr + initHour + \"_f\" + fhour + \".nc\"\n",
        "  ocePath = dataPath + \"mom6Output/\" + subfolder + oceFile\n",
        "  oceData = xr.open_dataset(ocePath, decode_times=False)\n",
        "\n",
        "  upperLayers = {\"top\":[0]*len(oceLayers[:-1]), \"incremental\":oceLayers[:-1]}[diffType]\n",
        "  for upperLayer, lowerLayer, oceAx in zip(upperLayers, oceLayers[1:], oceAxColumn):\n",
        "\n",
        "    upperSlice = oceData.isel(z_l=upperLayer, time=0).sel(xh=slice(lonMin, lonMax), yh=slice(latMin, latMax))\n",
        "    lowerSlice = oceData.isel(z_l=lowerLayer, time=0).sel(xh=slice(lonMin, lonMax), yh=slice(latMin, latMax))\n",
        "\n",
        "    tdiff = upperSlice.temp.data - lowerSlice.temp.data\n",
        "\n",
        "    maxContour = np.max(abs(tdiff[np.isnan(tdiff)==False]))+0.5\n",
        "    if \"Empty\" in contourLevs[lowerLayer]: contourLevs[lowerLayer] = np.round(np.linspace(-maxContour, maxContour, 20), 2)\n",
        "\n",
        "    #oceSlice = oceData.isel(z_l=oceLayer).sel(xh=slice(lonMin, lonMax), yh=slice(latMin, latMax), time=oceData.time.data[0]\n",
        "\n",
        "    tempContour = oceAx.contourf(lowerSlice.xh.data, lowerSlice.yh.data, tdiff, cmap=\"bwr\", transform=ccrs.PlateCarree(),\n",
        "                                extent=[lonMin, lonMax, latMin, latMax], levels=contourLevs[lowerLayer])\n",
        "    if valid == fcastTimes[-1]:\n",
        "      cax = oceFig.add_axes([oceAx.get_position().get_points()[1, 0]+0.02, oceAx.get_position().get_points()[0, 1], 0.01, 0.05])\n",
        "      oceFig.colorbar(tempContour, cax=cax, shrink=0.4, label=f\"T(z={round(oceData.z_l.data[upperLayer],1)}) - T(z={round(oceData.z_l.data[lowerLayer],1)})\")\n",
        "    if valid == fcastTimes[0]: oceAx.set_ylabel(f\"{round(oceData.z_l.data[upperLayer],1)} m - {round(oceData.z_l.data[lowerLayer],1)} m\")\n",
        "\n",
        "    oceAx.scatter(tcLocs[valid][1], tcLocs[valid][0], marker=\"*\", color=\"black\", s=200, transform=ccrs.PlateCarree())\n",
        "\n",
        "    gridLabels = []\n",
        "    if lowerLayer == oceLayers[-1]: gridLabels.append(\"bottom\")\n",
        "    if valid == fcastTimes[0]: gridLabels.append(\"left\")\n",
        "    oceAx.gridlines(draw_labels=gridLabels, alpha=0.5)\n",
        "\n",
        "    oceAx.add_feature(cft.COASTLINE)\n",
        "    oceAx.add_feature(cft.BORDERS)\n",
        "    oceAx.set_title(f\"T(z={round(oceData.z_l.data[upperLayer],1)}) - T(z={round(oceData.z_l.data[lowerLayer],1)})\" + \"\\n\" + valid.strftime('%m-%d %HUTC'), fontsize=20)\n",
        "\n",
        "    oceAx.set_extent([lonMin, lonMax, latMin, latMax])\n",
        "\n",
        "#oceFig.suptitle(f\"Initialized {initTime.strftime('%Y-%m-%d %HUTC')}\")"
      ],
      "metadata": {
        "id": "oaFlLfU4D8J4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ocean Salinity Difference by Level"
      ],
      "metadata": {
        "id": "KdgxKkRztzBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oceFig = plt.figure(figsize=(len(fcastTimes)*6,len(oceLayers)*7))\n",
        "oceAxes = [[oceFig.add_axes([xcorner, ycorner, xWidth-buffer, yWidth-buffer], projection=ccrs.PlateCarree()) for ycorner in ycorners[:-1]] for xcorner in xcorners]\n",
        "\n",
        "contourLevs = {layer:[\"Empty\"] for layer in oceLayers}\n",
        "\n",
        "for valid, oceAxColumn in zip(fcastTimes, oceAxes):\n",
        "\n",
        "  fhour = str(int((valid-initTime).total_seconds() / 3600))\n",
        "  while len(fhour) < 3: fhour = \"0\" + fhour\n",
        "\n",
        "  oceFile = \"mom6_\" + initStr + initHour + \"_f\" + fhour + \".nc\"\n",
        "  ocePath = dataPath + \"mom6Output/\" + subfolder + oceFile\n",
        "  oceData = xr.open_dataset(ocePath, decode_times=False)\n",
        "\n",
        "  upperLayers = {\"top\":[0]*len(oceLayers[:-1]), \"incremental\":oceLayers[:-1]}[diffType]\n",
        "  for upperLayer, lowerLayer, oceAx in zip(upperLayers, oceLayers[1:], oceAxColumn):\n",
        "\n",
        "    upperSlice = oceData.isel(z_l=upperLayer, time=0).sel(xh=slice(lonMin, lonMax), yh=slice(latMin, latMax))\n",
        "    lowerSlice = oceData.isel(z_l=lowerLayer, time=0).sel(xh=slice(lonMin, lonMax), yh=slice(latMin, latMax))\n",
        "\n",
        "    tdiff = upperSlice.so.data - lowerSlice.so.data\n",
        "\n",
        "    maxContour = np.max(abs(tdiff[np.isnan(tdiff)==False]))+0.5\n",
        "    if \"Empty\" in contourLevs[lowerLayer]: contourLevs[lowerLayer] = np.linspace(-2.5, 2.5, 16) #np.round(np.linspace(-maxContour, maxContour, 20), 2)\n",
        "\n",
        "    #oceSlice = oceData.isel(z_l=oceLayer).sel(xh=slice(lonMin, lonMax), yh=slice(latMin, latMax), time=oceData.time.data[0]\n",
        "\n",
        "    tempContour = oceAx.contourf(lowerSlice.xh.data, lowerSlice.yh.data, tdiff, cmap=\"PRGn\", transform=ccrs.PlateCarree(),\n",
        "                                extent=[lonMin, lonMax, latMin, latMax], levels=contourLevs[lowerLayer])\n",
        "    if valid == fcastTimes[-1]:\n",
        "      cax = oceFig.add_axes([oceAx.get_position().get_points()[1, 0]+0.02, oceAx.get_position().get_points()[0, 1], 0.01, 0.05])\n",
        "      oceFig.colorbar(tempContour, cax=cax, shrink=0.4, label=\"$\\Delta$psu\")\n",
        "    if valid == fcastTimes[0]: oceAx.set_ylabel(f\"{round(oceData.z_l.data[upperLayer],1)} m - {round(oceData.z_l.data[lowerLayer],1)} m\")\n",
        "\n",
        "    oceAx.scatter(tcLocs[valid][1], tcLocs[valid][0], marker=\"*\", color=\"black\", s=200, transform=ccrs.PlateCarree())\n",
        "\n",
        "    gridLabels = []\n",
        "    if lowerLayer == oceLayers[-1]: gridLabels.append(\"bottom\")\n",
        "    if valid == fcastTimes[0]: gridLabels.append(\"left\")\n",
        "    oceAx.gridlines(draw_labels=gridLabels, alpha=0.5)\n",
        "\n",
        "    oceAx.add_feature(cft.COASTLINE)\n",
        "    oceAx.add_feature(cft.BORDERS)\n",
        "    oceAx.set_title(f\"S(z={round(oceData.z_l.data[upperLayer],1)}) - S(z={round(oceData.z_l.data[lowerLayer],1)})\" + \"\\n\" + valid.strftime('%m-%d %HUTC'), fontsize=20)\n",
        "\n",
        "    oceAx.set_extent([lonMin, lonMax, latMin, latMax])\n",
        "\n",
        "#oceFig.suptitle(f\"Initialized {initTime.strftime('%Y-%m-%d %HUTC')}\")"
      ],
      "metadata": {
        "id": "DDBBs7uptzBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map of MLD"
      ],
      "metadata": {
        "id": "Q2TyxhprmCQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oceFig = plt.figure(figsize=(len(fcastTimes)*5, 6))\n",
        "oceAxes = [oceFig.add_axes([xcorner, 0.1, xWidth-buffer, 0.8], projection=ccrs.PlateCarree()) for xcorner in xcorners]\n",
        "\n",
        "for valid, oceAx in zip(fcastTimes, oceAxes):\n",
        "\n",
        "  fhour = str(int((valid-initTime).total_seconds() / 3600))\n",
        "  while len(fhour) < 3: fhour = \"0\" + fhour\n",
        "\n",
        "  oceFile = \"mom6_\" + initStr + initHour + \"_f\" + fhour + \".nc\"\n",
        "  ocePath = dataPath + \"mom6Output/\" + subfolder + oceFile\n",
        "  oceData = xr.open_dataset(ocePath, decode_times=False)\n",
        "\n",
        "  oceSlice = oceData.isel(z_l=oceLayer).sel(xh=slice(lonMin, lonMax), yh=slice(latMin, latMax), time=oceData.time.data[0])\n",
        "\n",
        "  mld = oceSlice.MLD_003.data\n",
        "  contourLevs = np.linspace(1, 81, 17) #np.round(np.linspace(min(mld[np.isnan(mld)==False])-1, max(mld[np.isnan(mld)==False])+1, 15))\n",
        "\n",
        "  tempContour = oceAx.contourf(oceSlice.xh.data, oceSlice.yh.data, mld, cmap=\"cividis_r\", transform=ccrs.PlateCarree(),\n",
        "                              extent=[lonMin, lonMax, latMin, latMax], levels=contourLevs)\n",
        "  if valid == fcastTimes[-1]:\n",
        "    cax = oceFig.add_axes([oceAx.get_position().get_points()[1, 0]+0.02, oceAx.get_position().get_points()[0, 1], 0.01, 0.3])\n",
        "    oceFig.colorbar(tempContour, cax=cax, shrink=0.5, label=\"MLD (m)\")\n",
        "\n",
        "  oceAx.scatter(tcLocs[valid][1], tcLocs[valid][0], marker=\"*\", color=\"black\", s=100, transform=ccrs.PlateCarree())\n",
        "\n",
        "  gridLabels = []\n",
        "  if oceLayer == oceLayers[-1]: gridLabels.append(\"bottom\")\n",
        "  if valid == fcastTimes[0]: gridLabels.append(\"left\")\n",
        "  oceAx.gridlines(draw_labels=gridLabels, alpha=0.5)\n",
        "\n",
        "  oceAx.add_feature(cft.COASTLINE)\n",
        "  oceAx.add_feature(cft.BORDERS)\n",
        "  oceAx.set_title(f\"{valid.strftime('%Y-%m-%d %HUTC')}\")\n",
        "\n",
        "  oceAx.set_extent([lonMin, lonMax, latMin, latMax])"
      ],
      "metadata": {
        "id": "xUxigsnHmBs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map of ocean depth (Assumes first nan value is bottom of the ocean)"
      ],
      "metadata": {
        "id": "x8ztG-Mo4JGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oceSlice = oceData.sel(xh=slice(lonMin, lonMax), yh=slice(latMin, latMax), time=oceData.time.data[0])\n",
        "nanDepths = np.zeros(shape=oceSlice.SST.data.shape)\n",
        "\n",
        "for i in range(len(oceSlice.yh.data)):\n",
        "  for j in range(len(oceSlice.xh.data)):\n",
        "    nanTemps = np.isnan(oceSlice.isel(xh=j, yh=i).temp.data)\n",
        "    if np.sum(nanTemps) == 0: nanDepths[i, j] = max(oceSlice.z_l.data)\n",
        "    else: nanDepths[i, j] = np.min(oceSlice.z_l.data[nanTemps])"
      ],
      "metadata": {
        "id": "tkY7D4xL8Phx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(6, 4))\n",
        "ax = fig.add_axes([0.1,0.1,0.8,0.8], projection=ccrs.PlateCarree())\n",
        "contour = ax.contourf(oceSlice.xh.data, oceSlice.yh.data, nanDepths, transform=ccrs.PlateCarree(), cmap=\"plasma_r\",\n",
        "             extent=[lonMin, lonMax, latMin, latMax], extend=\"both\")\n",
        "ax.coastlines()\n",
        "fig.colorbar(contour, shrink=0.5, label=\"Depth (m)\")"
      ],
      "metadata": {
        "id": "G-xSrMAy6cQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot of Vertical Model Resolution"
      ],
      "metadata": {
        "id": "onE8hqccR6jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resFig = plt.figure(figsize=(5, 8))\n",
        "atmAx = resFig.add_axes([0.1, 0.55, 0.8, 0.4])\n",
        "oceAx = resFig.add_axes([0.1, 0.05, 0.8, 0.4])\n",
        "\n",
        "atmAx.plot(np.arange(1, len(atmData.isobaricInhPa.data)+1), atmData.isobaricInhPa.data, label=\"Atmosphere\")\n",
        "atmAx.scatter(np.arange(1, len(atmData.isobaricInhPa.data)+1), atmData.isobaricInhPa.data)\n",
        "\n",
        "oceZ = oceData.z_l.data[oceData.z_l.data<=150]\n",
        "oceAx.plot(np.arange(1, len(oceZ)+1), oceZ, label=\"Ocean\")\n",
        "oceAx.scatter(np.arange(1, len(oceZ)+1), oceZ)\n",
        "oceAx.set_xticks(np.arange(1, len(oceZ), 3))\n",
        "\n",
        "atmAx.grid(alpha=0.5)\n",
        "atmAx.set_xlabel(\"# of Levels\")\n",
        "atmAx.set_ylabel(\"Pressure (hPa)\")\n",
        "atmAx.invert_yaxis()\n",
        "\n",
        "oceAx.grid(alpha=0.5)\n",
        "oceAx.set_xlabel(\"# of Levels\")\n",
        "oceAx.set_ylabel(\"Depth (m)\")\n",
        "oceAx.invert_yaxis()"
      ],
      "metadata": {
        "id": "ZnG6aK0jR6VU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Air-Sea Fluxes"
      ],
      "metadata": {
        "id": "d8TbMFJooUHi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paramaters for flux figures"
      ],
      "metadata": {
        "id": "9ZBk2gfmszOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "atmVars = [\"Total Heat Flux\", \"Latent Heat Flux\", \"Wind Speed\"]\n",
        "oceVars = []\n",
        "vars = atmVars + oceVars\n",
        "\n",
        "varUnits = {\"Momentum Flux\":\"N m$^{-2}$\", \"Latent Heat Flux\":\"W m$^{-2}$\", \"Total Heat Flux\":\"W m$^{-2}$\", \"SST\":\"K\", \"Wind Speed\":\"m s$^{-1}$\", \"MLD\":\"m\"}\n",
        "cmaps = {\"Momentum Flux\":\"cividis\", \"Latent Heat Flux\":\"summer_r\", \"Total Heat Flux\":\"cool_r\", \"SST\":\"coolwarm\", \"Wind Speed\":\"viridis\", \"MLD\":\"cividis_r\"}\n",
        "contourLevs = {\"Wind Speed\":np.linspace(0,80,17), \"Total Heat Flux\": np.linspace(-3300, 0, 12), \"Latent Heat Flux\":np.linspace(-2100, 100, 12),\n",
        "               \"Momentum Flux\": np.linspace(-12, 0, 13), \"SST\": np.linspace(300.0, 303.5, 15), \"MLD\":np.linspace(1, 66, 14)}\n",
        "\n",
        "buffer = 0.1 / len(vars)\n",
        "xWidth = 0.8 / len(fcastTimes)\n",
        "yWidth = 0.8 / len(vars)\n",
        "xcorners = np.arange(0.1,0.9,xWidth)\n",
        "ycorners = np.arange(0.1,0.8,yWidth)\n",
        "\n",
        "mapRadius = 0.8 #in degrees"
      ],
      "metadata": {
        "id": "5kqixPb4qlYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "allData = {valid:{} for valid in allTimes}\n",
        "allDims = {\"atm\":{\"lat\":{}, \"lon\":{}}, \"oce\":{\"lat\":{}, \"lon\":{}}}\n",
        "\n",
        "for valid in allTimes:\n",
        "\n",
        "  fhour = str(int((valid-initTime).total_seconds() / 3600))\n",
        "  while len(fhour) < 3: fhour = \"0\" + fhour\n",
        "\n",
        "  atmFile = \"hafsa_\" + initStr + initHour + \"_f\" + fhour + \".nc\"\n",
        "  atmPath = dataPath + \"hafsaOutput/\" + subfolder + atmFile\n",
        "  atmData = xr.open_dataset(atmPath, decode_timedelta=False)\n",
        "\n",
        "  lonMin, lonMax, latMin, latMax = tcLocs[valid][1]-mapRadius, tcLocs[valid][1]+mapRadius, tcLocs[valid][0]-mapRadius, tcLocs[valid][0]+mapRadius\n",
        "  atmSlice = atmData.sel(longitude=slice(lonMin+360, lonMax+360), latitude=slice(latMin, latMax))\n",
        "  allData[valid][\"Total Heat Flux\"] = (atmSlice.slhtf.data + atmSlice.ishf.data + atmSlice.sulwrf.data) * -1\n",
        "  allData[valid][\"Latent Heat Flux\"] = atmSlice.slhtf.data * -1\n",
        "  allData[valid][\"Momentum Flux\"] = (atmSlice.utaua.data**2 + atmSlice.vtaua.data**2)**0.5\n",
        "  allData[valid][\"SST\"] = atmSlice.sst.data\n",
        "  allData[valid][\"Wind Speed\"] = (atmSlice.u.sel(isobaricInhPa=1000.0).data**2 + atmSlice.v.sel(isobaricInhPa=1000.0).data**2)**0.5\n",
        "\n",
        "  if len(oceVars) != 0:\n",
        "    oceFile = \"mom6_\" + initStr + initHour + \"_f\" + fhour + \".nc\"\n",
        "    ocePath = dataPath + \"mom6Output/\" + subfolder + oceFile\n",
        "    oceData = xr.open_dataset(ocePath, decode_times=False)\n",
        "    oceSlice = oceData.sel(xh=slice(lonMin, lonMax), yh=slice(latMin, latMax), time=oceData.time.data[0])\n",
        "    allData[valid][\"MLD\"] = oceSlice.MLD_003.data #Using rho=0.03 as criteria\n",
        "\n",
        "  allDims[\"atm\"][\"lat\"][valid] = atmSlice.latitude.data\n",
        "  allDims[\"atm\"][\"lon\"][valid] = atmSlice.longitude.data\n",
        "  if len(oceVars) != 0:\n",
        "    allDims[\"oce\"][\"lat\"][valid] = oceSlice.yh.data\n",
        "    allDims[\"oce\"][\"lon\"][valid] = oceSlice.xh.data"
      ],
      "metadata": {
        "id": "U06txOzG6Qbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "atmFig = plt.figure(figsize=(len(fcastTimes)*4,len(vars)*4))\n",
        "atmAxes = [[atmFig.add_axes([xcorner, ycorner, xWidth-buffer, yWidth-buffer], projection=ccrs.PlateCarree()) for ycorner in ycorners] for xcorner in xcorners]\n",
        "\n",
        "for valid, atmAxColumn in zip(fcastTimes, atmAxes):\n",
        "  for var, atmAx in zip(vars, atmAxColumn):\n",
        "\n",
        "    data = allData[valid][var]\n",
        "    if var in atmVars: contour = atmAx.contourf(allDims[\"atm\"][\"lon\"][valid], allDims[\"atm\"][\"lat\"][valid], data, cmap=cmaps[var], transform=ccrs.PlateCarree(), levels=contourLevs[var])\n",
        "    if var in oceVars: contour = atmAx.contourf(allDims[\"oce\"][\"lon\"][valid], allDims[\"oce\"][\"lat\"][valid], data, cmap=cmaps[var], transform=ccrs.PlateCarree(), levels=contourLevs[var])\n",
        "\n",
        "    labelSides = []\n",
        "    if var == vars[-0]: labelSides.append(\"bottom\")\n",
        "    if valid == fcastTimes[0]: labelSides.append(\"left\")\n",
        "    atmAx.gridlines(draw_labels=labelSides, alpha=0.5)\n",
        "\n",
        "    atmAx.set_title(valid.strftime('%m-%d %HUTC'), fontsize=16)\n",
        "    atmAx.add_feature(cft.COASTLINE)\n",
        "    atmAx.add_feature(cft.BORDERS)\n",
        "\n",
        "    cbarTicks = [contourLevs[var][i] for i in range(len(contourLevs[var])) if i%2 == 0]\n",
        "    if valid == fcastTimes[-1]:\n",
        "      cax = atmFig.add_axes([atmAx.get_position().get_points()[1, 0]+0.03, atmAx.get_position().get_points()[0, 1]+0.02, 0.01, 0.14])\n",
        "      cbar = atmFig.colorbar(contour, cax=cax, ticks=cbarTicks)\n",
        "      cbar.set_label(label=f\"{var} ({varUnits[var]})\", fontsize=16)\n",
        "\n",
        "    lonMin, lonMax, latMin, latMax = tcLocs[valid][1]-mapRadius, tcLocs[valid][1]+mapRadius, tcLocs[valid][0]-mapRadius, tcLocs[valid][0]+mapRadius\n",
        "    atmAx.set_extent([lonMin, lonMax, latMin, latMax])"
      ],
      "metadata": {
        "id": "qKSxxaV3oaq6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "082321b9"
      },
      "source": [
        "# Cannot currently calculate correlation for ocean variables due to differing resolutions\n",
        "# Get the shape of the data arrays (assuming all variables have the same spatial dimensions)\n",
        "lat_dim = len(allDims[\"atm\"][\"lat\"][fcastTimes[0]])\n",
        "lon_dim = len(allDims[\"atm\"][\"lon\"][fcastTimes[0]])\n",
        "#lon_dim = allData[fcastTimes[0]][\"Total Heat Flux\"].shape\n",
        "\n",
        "# Initialize a dictionary to store correlation coefficients\n",
        "correlation_data = {}\n",
        "correlation_pairs = [\n",
        "    (\"Total Heat Flux\", \"SST\"),\n",
        "    (\"Latent Heat Flux\", \"SST\"),\n",
        "    (\"Total Heat Flux\", \"Wind Speed\"),\n",
        "    (\"Latent Heat Flux\", \"Wind Speed\")]\n",
        "\n",
        "for fluxVar, envVar in correlation_pairs:\n",
        "    correlation_data[fluxVar.lower()+envVar.lower()] = np.full((lat_dim, lon_dim), np.nan)\n",
        "\n",
        "# Iterate through each spatial point\n",
        "for i in range(lat_dim):\n",
        "    for j in range(lon_dim):\n",
        "        # Extract time series data for the current spatial point\n",
        "        time_series_data = {}\n",
        "        for var in set([pair[0] for pair in correlation_pairs] + [pair[1] for pair in correlation_pairs]):\n",
        "            time_series_data[var] = np.array([allData[valid][var][i, j] for valid in allTimes])\n",
        "\n",
        "        # Remove NaN values from the time series\n",
        "        valid_indices = ~np.isnan(time_series_data[correlation_pairs[0][0]]) # Use one of the variables to check for valid indices\n",
        "        for var in time_series_data:\n",
        "            valid_indices = valid_indices & ~np.isnan(time_series_data[var])\n",
        "\n",
        "        # Calculate correlation only if there are enough valid data points (at least 2 for correlation)\n",
        "        for fluxVar, envVar in correlation_pairs:\n",
        "            ts1_valid = time_series_data[fluxVar][valid_indices]\n",
        "            ts2_valid = time_series_data[envVar][valid_indices]\n",
        "            if len(ts1_valid) >= 2 and len(ts2_valid) >= 2:\n",
        "                correlation_data[fluxVar.lower()+envVar.lower()][i, j] = np.corrcoef(ts1_valid, ts2_valid)[0, 1] * -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "envVar = \"wind speed\"\n",
        "\n",
        "for valid, axColumn in zip(fcastTimes, atmAxes):\n",
        "  for var, ax in zip(vars, axColumn):\n",
        "    if var == \"Total Heat Flux\":\n",
        "      c = ax.contour(allDims[\"atm\"][\"lon\"][valid], allDims[\"atm\"][\"lat\"][valid], correlation_data[var.lower()+envVar.lower()], transform=ccrs.PlateCarree(), levels=np.arange(0.3, 1, 0.3), colors=[\"blue\", \"purple\", \"red\"])\n",
        "      ax.clabel(c)\n",
        "    if var == \"Latent Heat Flux\":\n",
        "      c = ax.contour(allDims[\"atm\"][\"lon\"][valid], allDims[\"atm\"][\"lat\"][valid], correlation_data[var.lower()+envVar.lower()], transform=ccrs.PlateCarree(), levels=np.arange(0.3, 1, 0.3), colors=[\"blue\", \"purple\", \"red\"])\n",
        "      ax.clabel(c)\n",
        "\n",
        "    if radType == \"wind\":\n",
        "      rect = patches.Rectangle((tcLocs[valid][1]-(windRads[valid]*0.5), tcLocs[valid][0]-(windRads[valid]*0.5)), windRads[valid], windRads[valid], linewidth=1, edgecolor='k', facecolor='none')\n",
        "      ax.add_patch(rect)\n",
        "    if radType == \"dist\":\n",
        "      rect = patches.Rectangle((tcLocs[valid][1]-(dist*0.5), tcLocs[valid][0]-(dist*0.5)), dist, dist, linewidth=1, edgecolor='k', facecolor='none')\n",
        "      ax.add_patch(rect)\n",
        "\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)"
      ],
      "metadata": {
        "id": "Dste9Ys41H9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "atmFig"
      ],
      "metadata": {
        "id": "3Bckwb-i22RM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}